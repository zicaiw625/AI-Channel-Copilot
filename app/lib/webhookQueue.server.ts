import prisma from "../db.server";
import { withAdvisoryLockSimple } from "./locks.server";
import { getQueueConfig } from "./env.server";
import { Prisma } from "@prisma/client";
import { logger, type LogContext } from "./logger.server";

type WebhookJob = {
  shopDomain: string;
  topic: string;
  intent: string;
  payload: Record<string, unknown>;
  externalId?: string | null;
  orderId?: string | null;
  eventTime?: Date | null;
  run: (payload: Record<string, unknown>) => Promise<void>;
};

const processingKeys = new Set<string>();
const scheduledTimers = new Map<string, NodeJS.Timeout>();
const lastRecoveryTime = new Map<string, number>(); // è®°å½•ä¸Šæ¬¡æ¢å¤æ—¶é—´ï¼Œé™åˆ¶æ¢å¤é¢‘ç‡
const queue = getQueueConfig();

// é…ç½®å¸¸é‡
const MAX_RETRIES = queue.maxRetries;
const BASE_DELAY_MS = queue.baseDelayMs;
const MAX_DELAY_MS = queue.maxDelayMs;
const PENDING_COOLDOWN_MS = queue.pendingCooldownMs;
const MAX_BATCH = queue.maxBatch;
const PENDING_MAX_COOLDOWN_MS = queue.pendingMaxCooldownMs;
const STUCK_JOB_TIMEOUT_MS = 5 * 60 * 1000; // 5 åˆ†é’Ÿ
const MAX_RECURSIVE_DEPTH = 100;
const MAX_PAYLOAD_SIZE = 64 * 1024; // 64KB payload å¤§å°é™åˆ¶
const RECOVERY_INTERVAL_MS = 60_000; // 1 åˆ†é’Ÿæ¢å¤æ£€æŸ¥é—´éš”
const MAX_HANDLERS = 100; // handlers Map æœ€å¤§å®¹é‡

// æ˜¯å¦æ­£åœ¨å…³é—­
let isShuttingDown = false;
let activeJobCount = 0;

// æ¸…ç†æ‰€æœ‰ scheduled timersï¼ˆç”¨äºä¼˜é›…å…³é—­ï¼‰
const cleanupAllTimers = () => {
  for (const [key, timer] of scheduledTimers.entries()) {
    clearTimeout(timer);
    scheduledTimers.delete(key);
  }
  lastRecoveryTime.clear();
  logger.info("[webhook] All scheduled timers cleaned up", { count: scheduledTimers.size });
};

/**
 * ä¼˜é›…å…³é—­ï¼šç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ
 */
const gracefulShutdown = async (signal: string) => {
  if (isShuttingDown) return;
  isShuttingDown = true;
  
  logger.info("[webhook] Graceful shutdown initiated", { signal, activeJobs: activeJobCount });
  
  // æ¸…ç†å®šæ—¶å™¨ï¼Œé˜»æ­¢æ–°ä»»åŠ¡è°ƒåº¦
  cleanupAllTimers();
  
  // ç­‰å¾…è¿›è¡Œä¸­çš„ä»»åŠ¡å®Œæˆï¼ˆæœ€å¤šç­‰å¾… 30 ç§’ï¼‰
  const maxWait = 30_000;
  const startTime = Date.now();
  
  while (activeJobCount > 0 && Date.now() - startTime < maxWait) {
    await new Promise(resolve => setTimeout(resolve, 100));
  }
  
  if (activeJobCount > 0) {
    logger.warn("[webhook] Forced shutdown with active jobs", { activeJobs: activeJobCount });
  } else {
    logger.info("[webhook] Graceful shutdown completed");
  }
};

// æ³¨å†Œè¿›ç¨‹é€€å‡ºæ—¶çš„æ¸…ç†é’©å­
if (typeof process !== "undefined") {
  const exitHandler = (signal: string) => () => {
    void gracefulShutdown(signal);
  };
  
  process.once("beforeExit", exitHandler("beforeExit"));
  process.once("SIGINT", exitHandler("SIGINT"));
  process.once("SIGTERM", exitHandler("SIGTERM"));
}

// å¯¼å‡ºæ¸…ç†å‡½æ•°ä¾›æµ‹è¯•æˆ–æ‰‹åŠ¨è°ƒç”¨
export const cleanupWebhookTimers = cleanupAllTimers;

/**
 * FNV-1a å“ˆå¸Œç®—æ³• - æ¯” djb2 æœ‰æ›´å¥½çš„åˆ†å¸ƒ
 */
const hashKey = (value: string): number => {
  let hash = 2166136261; // FNV offset basis
  for (let i = 0; i < value.length; i++) {
    hash ^= value.charCodeAt(i);
    hash = Math.imul(hash, 16777619); // FNV prime
  }
  // ç¡®ä¿è¿”å›æ­£æ•°ï¼ŒèŒƒå›´åœ¨ 1100 - 1100999
  return 1100 + Math.abs(hash % 1000000);
};

/**
 * å®‰å…¨çš„é”™è¯¯æ¶ˆæ¯æå– - é¿å…æ³„éœ²æ•æ„Ÿä¿¡æ¯
 */
const sanitizeErrorMessage = (error: unknown): string => {
  if (error instanceof Error) {
    const sensitivePatterns = [
      /password/i,
      /secret/i,
      /token/i,
      /api[_-]?key/i,
      /connection.*string/i,
      /postgres:\/\//i,
      /mysql:\/\//i,
    ];
    
    const message = error.message;
    for (const pattern of sensitivePatterns) {
      if (pattern.test(message)) {
        return "Internal error (details redacted)";
      }
    }
    
    return message.length > 500 ? message.slice(0, 500) + "..." : message;
  }
  
  if (typeof error === "string") {
    return error.length > 500 ? error.slice(0, 500) + "..." : error;
  }
  
  return "Unknown error";
};

/**
 * é™é¢‘çš„å¡ä½ä»»åŠ¡æ¢å¤
 * æ¯ä¸ªåº—é“ºæœ€å¤šæ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
 */
const recoverStuckJobs = async (shopDomain: string) => {
  // æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œæ¢å¤ï¼ˆé™é¢‘ï¼‰
  const lastTime = lastRecoveryTime.get(shopDomain) || 0;
  if (Date.now() - lastTime < RECOVERY_INTERVAL_MS) {
    return; // è·³è¿‡ï¼Œè·ç¦»ä¸Šæ¬¡æ£€æŸ¥ä¸è¶³ 1 åˆ†é’Ÿ
  }
  lastRecoveryTime.set(shopDomain, Date.now());
  
  // æ¸…ç†è¿‡æœŸçš„æ¢å¤æ—¶é—´è®°å½•ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
  if (lastRecoveryTime.size > 10000) {
    const cutoff = Date.now() - RECOVERY_INTERVAL_MS * 2;
    for (const [key, time] of lastRecoveryTime) {
      if (time < cutoff) {
        lastRecoveryTime.delete(key);
      }
    }
  }

  try {
    const threshold = new Date(Date.now() - STUCK_JOB_TIMEOUT_MS);
    const result = await prisma.webhookJob.updateMany({
      where: {
        shopDomain,
        status: "processing",
        startedAt: { lt: threshold },
      },
      data: {
        status: "queued",
        startedAt: null,
        error: "Recovered from stuck state",
      },
    });
    if (result.count > 0) {
      logger.warn("[webhook] recovered stuck jobs", { shopDomain, count: result.count });
    }
  } catch (error) {
    logger.error("[webhook] failed to recover stuck jobs", { 
      shopDomain, 
      error: sanitizeErrorMessage(error) 
    });
  }
};

const dequeue = async (extraWhere?: Prisma.WebhookJobWhereInput) => {
  return prisma.$transaction(async (tx) => {
    const now = new Date();
    const baseWhere: Prisma.WebhookJobWhereInput = { status: "queued", OR: [{ nextRunAt: null }, { nextRunAt: { lte: now } }] };
    const where = extraWhere ? { AND: [baseWhere, extraWhere] } : baseWhere;
    const pending = await tx.webhookJob.findFirst({
      where,
      orderBy: [{ nextRunAt: "asc" }, { id: "asc" }],
    });

    if (!pending) return null;

    const claimed = await tx.webhookJob.updateMany({
      where: { id: pending.id, status: "queued" },
      data: { status: "processing", startedAt: new Date() },
    });

    if (!claimed.count) {
      logger.debug("[webhook] failed to claim job", {
        jobId: pending.id,
        shopDomain: pending.shopDomain,
        status: pending.status,
      });
      return null;
    }

    return tx.webhookJob.findUnique({ where: { id: pending.id } });
  });
};

/**
 * æ›´æ–°ä»»åŠ¡çŠ¶æ€
 */
const updateJobStatus = async (
  id: number,
  status: "completed" | "failed",
  error?: string,
) => {
  try {
    const result = await prisma.webhookJob.updateMany({
      where: { id },
      data: { 
        status, 
        finishedAt: new Date(), 
        ...(error ? { error: error.slice(0, 1000) } : {}) // é™åˆ¶é”™è¯¯æ¶ˆæ¯é•¿åº¦
      },
    });

    if (!result.count) {
      logger.warn("[webhook] job status update skipped (job missing)", {
        jobId: id,
        targetStatus: status,
      });
    }
  } catch (err) {
    logger.error("[webhook] failed to update job status", {
      jobId: id,
      targetStatus: status,
      error: sanitizeErrorMessage(err),
    });
  }
};

// removed unused global processing loop in favor of per-shop processing

/**
 * LRU Handler Cache
 * ä½¿ç”¨æ—¶é—´æˆ³è¿½è¸ªæœ€åä½¿ç”¨æ—¶é—´ï¼Œå®ç°çœŸæ­£çš„ LRU æ·˜æ±°ç­–ç•¥
 */
type HandlerEntry = {
  handler: WebhookJob["run"];
  lastUsedAt: number;
};

const handlers = new Map<string, HandlerEntry>();

/**
 * æ³¨å†Œ webhook handlerï¼ˆå¸¦ LRU è¿½è¸ªï¼‰
 */
export const registerWebhookHandler = (
  intent: string,
  handler: WebhookJob["run"],
) => {
  handlers.set(intent, {
    handler,
    lastUsedAt: Date.now(),
  });
};

/**
 * è·å– handler å¹¶æ›´æ–° LRU æ—¶é—´æˆ³
 */
const getHandler = (intent: string): WebhookJob["run"] | undefined => {
  const entry = handlers.get(intent);
  if (entry) {
    // æ›´æ–°æœ€åä½¿ç”¨æ—¶é—´
    entry.lastUsedAt = Date.now();
    return entry.handler;
  }
  return undefined;
};

/**
 * çœŸæ­£çš„ LRU æ·˜æ±°ï¼šåˆ é™¤æœ€ä¸å¸¸ç”¨çš„ handler
 * ä¿ç•™æœ€è¿‘ä½¿ç”¨çš„ handlerï¼Œåˆ é™¤æœ€ä¹…æœªä½¿ç”¨çš„
 */
const evictLRUHandlers = (targetSize: number) => {
  if (handlers.size <= targetSize) return;
  
  // æŒ‰æœ€åä½¿ç”¨æ—¶é—´æ’åº
  const entries = Array.from(handlers.entries())
    .sort((a, b) => a[1].lastUsedAt - b[1].lastUsedAt);
  
  // åˆ é™¤æœ€ä¹…æœªä½¿ç”¨çš„ï¼Œç›´åˆ°è¾¾åˆ°ç›®æ ‡å¤§å°
  const toDelete = handlers.size - targetSize;
  for (let i = 0; i < toDelete && i < entries.length; i++) {
    handlers.delete(entries[i][0]);
  }
  
  logger.debug("[webhook] LRU eviction completed", {
    deleted: toDelete,
    remaining: handlers.size,
  });
};

/**
 * å…¥é˜Ÿ Webhook ä»»åŠ¡
 */
export const enqueueWebhookJob = async (job: WebhookJob) => {
  // å¦‚æœæ­£åœ¨å…³é—­ï¼Œæ‹’ç»æ–°ä»»åŠ¡
  if (isShuttingDown) {
    logger.warn("[webhook] job rejected: server is shutting down", { 
      shopDomain: job?.shopDomain, 
      intent: job?.intent 
    });
    return;
  }

  // åŸºç¡€éªŒè¯
  if (!job || typeof job !== "object") {
    logger.warn("[webhook] job rejected: invalid job object");
    return;
  }
  
  if (!job.shopDomain || typeof job.shopDomain !== "string") {
    logger.warn("[webhook] job rejected: missing shopDomain");
    return;
  }
  
  const payloadIsObject = job.payload && typeof job.payload === "object";
  if (!payloadIsObject) {
    logger.warn("[webhook] payload rejected: must be object", { 
      shopDomain: job.shopDomain, 
      intent: job.intent 
    });
    return;
  }

  // Payload å¤§å°æ£€æŸ¥
  try {
    const payloadSize = JSON.stringify(job.payload).length;
    if (payloadSize > MAX_PAYLOAD_SIZE) {
      logger.error("[webhook] payload rejected: too large", {
        shopDomain: job.shopDomain,
        intent: job.intent,
        size: payloadSize,
        maxSize: MAX_PAYLOAD_SIZE,
      });
      return;
    }
  } catch (err) {
    logger.error("[webhook] payload rejected: not serializable", {
      shopDomain: job.shopDomain,
      error: sanitizeErrorMessage(err),
    });
    return;
  }

  // æ³¨å†Œ handlerï¼ˆå¸¦ LRU æ·˜æ±°ç­–ç•¥ï¼‰
  if (!handlers.has(job.intent)) {
    // å¦‚æœè¾¾åˆ°å®¹é‡é™åˆ¶ï¼Œä½¿ç”¨ LRU ç­–ç•¥æ·˜æ±°æ—§ handler
    if (handlers.size >= MAX_HANDLERS) {
      logger.warn("[webhook] handlers map at capacity, evicting LRU entries", { 
        size: handlers.size,
        maxHandlers: MAX_HANDLERS,
      });
      // ä¿ç•™ 70% çš„ handlerï¼ˆåˆ é™¤æœ€ä¹…æœªä½¿ç”¨çš„ 30%ï¼‰
      evictLRUHandlers(Math.floor(MAX_HANDLERS * 0.7));
    }
    handlers.set(job.intent, {
      handler: job.run,
      lastUsedAt: Date.now(),
    });
  } else {
    // æ›´æ–°å·²å­˜åœ¨ handler çš„æœ€åä½¿ç”¨æ—¶é—´
    const entry = handlers.get(job.intent);
    if (entry) {
      entry.lastUsedAt = Date.now();
    }
  }

  // ä½¿ç”¨ try-catch å¤„ç†å”¯ä¸€çº¦æŸå†²çªï¼Œè€Œä¸æ˜¯å…ˆæŸ¥è¯¢
  // è¿™æ ·æ›´é«˜æ•ˆï¼Œå› ä¸ºå¤§å¤šæ•°æƒ…å†µä¸‹ä¸ä¼šæœ‰é‡å¤
  try {
    await prisma.webhookJob.create({
      data: {
        shopDomain: job.shopDomain,
        topic: job.topic,
        intent: job.intent,
        payload: job.payload as Prisma.InputJsonValue,
        externalId: job.externalId || null,
        orderId: job.orderId || null,
        eventTime: job.eventTime || null,
        attempts: 0,
        nextRunAt: new Date(),
      },
    });
  } catch (err) {
    // æ£€æŸ¥æ˜¯å¦æ˜¯å”¯ä¸€çº¦æŸå†²çª
    if (err instanceof Prisma.PrismaClientKnownRequestError && err.code === "P2002") {
      logger.info("[webhook] duplicate ignored by unique constraint", { 
        shopDomain: job.shopDomain, 
        topic: job.topic,
        externalId: job.externalId,
      });
      return;
    }
    // å…¶ä»–é”™è¯¯æŠ›å‡º
    throw err;
  }

  // é¢å¤–çš„ orderId å»é‡æ£€æŸ¥ï¼ˆé’ˆå¯¹åŒä¸€è®¢å•çš„æ´»è·ƒä»»åŠ¡ï¼‰
  if (job.orderId) {
    const activeCount = await prisma.webhookJob.count({
      where: {
        shopDomain: job.shopDomain,
        topic: job.topic,
        orderId: job.orderId,
        status: { in: ["queued", "processing"] },
      },
    });
    // å¦‚æœæœ‰å¤šä¸ªæ´»è·ƒä»»åŠ¡ï¼Œè¯´æ˜åˆšåˆ›å»ºçš„æ˜¯é‡å¤çš„
    if (activeCount > 1) {
      logger.info("[webhook] duplicate detected by orderId, will be processed once", { 
        shopDomain: job.shopDomain, 
        topic: job.topic,
        orderId: job.orderId,
      });
    }
  }

  if (!handlers.has(job.intent)) {
    logger.warn("[webhook] enqueued job without registered handler", {
      jobType: "webhook",
      intent: job.intent,
    });
  }

  void processWebhookQueueForShop(job.shopDomain);
};

export const getWebhookQueueSize = async () =>
  prisma.webhookJob.count({ where: { status: { in: ["queued", "processing"] } } });

export const getDeadLetterJobs = async (limit = 50) =>
  prisma.webhookJob.findMany({ where: { status: "failed" }, orderBy: { finishedAt: "desc" }, take: limit });

/**
 * ğŸ†• é˜Ÿåˆ—å”¤é†’æ‰«æå™¨
 * æ‰«æ DB ä¸­æ‰€æœ‰ due çš„ä»»åŠ¡ï¼Œè§¦å‘å„åº—é“ºçš„é˜Ÿåˆ—å¤„ç†
 * ç”¨äºè§£å†³è¿›ç¨‹é‡å¯å setTimeout ä¸¢å¤±å¯¼è‡´çš„ä»»åŠ¡å¡æ­»é—®é¢˜
 * 
 * å¤šå®ä¾‹éƒ¨ç½²æ—¶ï¼Œä¾èµ–ç°æœ‰çš„ advisory lock æœºåˆ¶é¿å…é‡å¤æ¶ˆè´¹
 */
export const wakeupDueWebhookJobs = async (): Promise<{ shopsWoken: number }> => {
  if (isShuttingDown) {
    return { shopsWoken: 0 };
  }

  try {
    const now = new Date();
    
    // æŸ¥æ‰¾æ‰€æœ‰æœ‰ due ä»»åŠ¡çš„åº—é“ºï¼ˆdistinct shopDomainï¼‰
    const shopsWithDueJobs = await prisma.webhookJob.groupBy({
      by: ["shopDomain"],
      where: {
        status: "queued",
        OR: [
          { nextRunAt: null },
          { nextRunAt: { lte: now } },
        ],
      },
      _count: { _all: true },
    });

    if (shopsWithDueJobs.length === 0) {
      return { shopsWoken: 0 };
    }

    logger.info("[webhook] Wakeup scanner found due jobs", {
      shopsCount: shopsWithDueJobs.length,
      totalJobs: shopsWithDueJobs.reduce((sum, s) => sum + s._count._all, 0),
    });

    // è§¦å‘å„åº—é“ºçš„é˜Ÿåˆ—å¤„ç†ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰
    for (const shop of shopsWithDueJobs) {
      void processWebhookQueueForShop(shop.shopDomain);
    }

    return { shopsWoken: shopsWithDueJobs.length };
  } catch (error) {
    logger.error("[webhook] Wakeup scanner failed", {
      error: sanitizeErrorMessage(error),
    });
    return { shopsWoken: 0 };
  }
};

/**
 * ğŸ†• æ—©æœŸå»é‡æ£€æŸ¥ï¼ˆShopify æœ€ä½³å®è·µï¼‰
 * åœ¨å…¥é˜Ÿå‰æ£€æŸ¥ X-Shopify-Webhook-Id æ˜¯å¦å·²å¤„ç†
 * è¿™æ¯”ä¾èµ–æ•°æ®åº“å”¯ä¸€çº¦æŸæ›´é«˜æ•ˆï¼Œé¿å…ä¸å¿…è¦çš„å…¥é˜Ÿå’Œå¤„ç†
 * 
 * @param shopDomain - åº—é“ºåŸŸå
 * @param topic - Webhook ä¸»é¢˜
 * @param externalId - X-Shopify-Webhook-Id
 * @returns æ˜¯å¦ä¸ºé‡å¤çš„ webhook
 */
export const checkWebhookDuplicate = async (
  shopDomain: string,
  topic: string,
  externalId: string,
): Promise<boolean> => {
  if (!externalId) return false;
  
  try {
    // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„ webhookï¼ˆä»»ä½•çŠ¶æ€ï¼‰
    const existing = await prisma.webhookJob.findFirst({
      where: {
        shopDomain,
        topic,
        externalId,
      },
      select: { id: true, status: true },
    });
    
    if (existing) {
      // è®°å½•é‡å¤ webhook çš„ç›‘æ§æŒ‡æ ‡
      logger.debug("[webhook] Duplicate detected by externalId", {
        shopDomain,
        topic,
        externalId,
        existingStatus: existing.status,
      });
      return true;
    }
    
    return false;
  } catch (error) {
    // æŸ¥è¯¢å¤±è´¥æ—¶ä¸é˜»æ­¢æ­£å¸¸å¤„ç†ï¼Œè®°å½•è­¦å‘Šåç»§ç»­
    logger.warn("[webhook] Duplicate check failed, proceeding", {
      shopDomain,
      topic,
      error: sanitizeErrorMessage(error),
    });
    return false;
  }
};

/**
 * å¤„ç†æŒ‡å®šåº—é“ºçš„ Webhook é˜Ÿåˆ—
 * ä½¿ç”¨æ¨¡å—çº§ handlers Mapï¼Œæ— éœ€å¤–éƒ¨ä¼ å…¥
 */
export const processWebhookQueueForShop = async (
  shopDomain: string,
  _handlers?: Map<string, WebhookJob["run"]>, // ä¿ç•™å‚æ•°ç­¾åå…¼å®¹æ€§ï¼Œä½†ä¸å†ä½¿ç”¨
  recursiveDepth = 0,
) => {
  if (!shopDomain) return;
  
  // å¦‚æœæ­£åœ¨å…³é—­ï¼Œä¸å¤„ç†æ–°ä»»åŠ¡
  if (isShuttingDown) return;
  
  const key = `shop:${shopDomain}`;
  
  // é˜²æ­¢å¹¶å‘å¤„ç†åŒä¸€åº—é“º
  if (processingKeys.has(key)) return;
  
  // é˜²æ­¢æ— é™é€’å½’
  if (recursiveDepth >= MAX_RECURSIVE_DEPTH) {
    logger.warn("[webhook] max recursive depth reached", { 
      shopDomain, 
      depth: recursiveDepth 
    });
    return;
  }
  
  processingKeys.add(key);
  
  // æ¸…ç†å·²æœ‰çš„å®šæ—¶å™¨
  const existingTimer = scheduledTimers.get(key);
  if (existingTimer) {
    clearTimeout(existingTimer);
    scheduledTimers.delete(key);
  }
  
  // æ¢å¤å¡ä½çš„ä»»åŠ¡ï¼ˆé™é¢‘ï¼‰
  await recoverStuckJobs(shopDomain);

  try {
    await withAdvisoryLockSimple(hashKey(key), async () => {
      let processed = 0;
      
      while (processed < Math.max(1, MAX_BATCH)) {
        // æ£€æŸ¥æ˜¯å¦æ­£åœ¨å…³é—­
        if (isShuttingDown) break;
        
        const job = await dequeue({ shopDomain });
        if (!job) break;

        activeJobCount++;
        const startedAt = Date.now();
        // ä½¿ç”¨ getHandler è·å– handler å¹¶æ›´æ–° LRU æ—¶é—´æˆ³
        const handler = getHandler(job.intent);
        const context: LogContext = {
          shopDomain: job.shopDomain,
          jobId: job.id,
          jobType: "webhook",
          intent: job.intent,
        };

        if (!handler) {
          logger.warn("[webhook] no handler registered", context, { topic: job.topic });
          await updateJobStatus(job.id, "failed", "no handler registered");
          activeJobCount--;
          processed++;
          continue;
        }

        try {
          await handler(job.payload as Record<string, unknown>);
          await updateJobStatus(job.id, "completed");
          logger.info("[webhook] job completed", context, {
            topic: job.topic,
            elapsedMs: Date.now() - startedAt,
          });
        } catch (error) {
          const message = sanitizeErrorMessage(error);
          logger.error("[webhook] job failed", context, {
            topic: job.topic,
            message,
          });

          const attempts = job.attempts || 0;
          if (attempts < MAX_RETRIES) {
            const jitter = Math.floor(Math.random() * BASE_DELAY_MS);
            const calc = BASE_DELAY_MS * Math.pow(2, attempts) + jitter;
            const nextDelay = Math.min(MAX_DELAY_MS, calc);
            const nextRun = new Date(Date.now() + nextDelay);
            
            try {
              await prisma.webhookJob.update({
                where: { id: job.id },
                data: {
                  status: "queued",
                  error: message.slice(0, 1000),
                  attempts: attempts + 1,
                  nextRunAt: nextRun,
                  finishedAt: null,
                },
              });
              logger.warn("[webhook] job scheduled for retry", context, { 
                attempts: attempts + 1, 
                nextDelay 
              });
            } catch (updateErr) {
              logger.error("[webhook] failed to schedule retry", context, {
                error: sanitizeErrorMessage(updateErr),
              });
              await updateJobStatus(job.id, "failed", message);
            }
          } else {
            await updateJobStatus(job.id, "failed", message);
          }
        } finally {
          activeJobCount--;
        }
        processed++;
      }
    });
  } catch (lockError) {
    logger.error("[webhook] processing failed", { 
      shopDomain, 
      error: sanitizeErrorMessage(lockError) 
    });
  } finally {
    processingKeys.delete(key);
  }
  
  // å¦‚æœæ­£åœ¨å…³é—­ï¼Œä¸è°ƒåº¦æ–°çš„å¤„ç†ï¼ˆç§»å‡º finally å—é¿å… no-unsafe-finallyï¼‰
  if (isShuttingDown) return;
  
  // æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¾…å¤„ç†ä»»åŠ¡
  try {
    const pending = await prisma.webhookJob.count({ 
      where: { status: "queued", shopDomain } 
    });
    
    if (pending > 0) {
      const dynamicDelay = Math.min(
        PENDING_COOLDOWN_MS + Math.floor(pending / Math.max(1, MAX_BATCH)) * 50, 
        PENDING_MAX_COOLDOWN_MS
      );
      
      const timer = setTimeout(() => {
        scheduledTimers.delete(key);
        void processWebhookQueueForShop(shopDomain, undefined, recursiveDepth + 1);
      }, dynamicDelay);
      
      scheduledTimers.set(key, timer);
    }
  } catch (countError) {
    logger.error("[webhook] failed to check pending jobs", { 
      shopDomain, 
      error: sanitizeErrorMessage(countError) 
    });
  }
};
